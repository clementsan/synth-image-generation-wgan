{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN synthetic image generation - TargetClass - 256 size - grayscale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup CUDA_VISIBLE DEVICES for titan.sci.utah.edu\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.conv_learner import *\n",
    "from fastai.transforms import *\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and hyper-parameters\n",
    "\n",
    "path = '~/Project_SEM/Project_GAN/data'\n",
    "\n",
    "csv_full = os.path.join(os.getcwd(),'Dataset_GAN_TargetClass_size256_Analysis.csv')\n",
    "csv = os.path.join(os.getcwd(),'Dataset_GAN_TargetClass_size256_Analysis_sample.csv')\n",
    "# Image size\n",
    "sz = 256\n",
    "# Batch size\n",
    "bs = 100\n",
    "# nz: size of input vector for Generator?\n",
    "nz = 300\n",
    "# Learning rate\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TMP_PATH = Path(os.path.join(os.getcwd(),'tmp'))\n",
    "TMP_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV file - create sample dataset\n",
    "df = pd.read_csv(csv_full, sep=',')\n",
    "df = df.sample(frac=0.5).reset_index(drop=True)\n",
    "df.to_csv(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, ni, no, ks, stride, bn=True, pad=None):\n",
    "        super().__init__()\n",
    "        if pad is None: pad = ks//2//stride\n",
    "        self.conv = nn.Conv2d(ni, no, ks, stride, padding=pad, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(no) if bn else None\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv(x))\n",
    "        return self.bn(x) if self.bn else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN_D(nn.Module):\n",
    "    def __init__(self, isize, nc, ndf, n_extra_layers=0):\n",
    "        super().__init__()\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        self.initial = ConvBlock(nc, ndf, 4, 2, bn=False)\n",
    "        csize,cndf = isize/2,ndf\n",
    "        self.extra = nn.Sequential(*[ConvBlock(cndf, cndf, 3, 1)\n",
    "                                    for t in range(n_extra_layers)])\n",
    "\n",
    "        pyr_layers = []\n",
    "        while csize > 4:\n",
    "            pyr_layers.append(ConvBlock(cndf, cndf*2, 4, 2))\n",
    "            cndf *= 2; csize /= 2\n",
    "        self.pyramid = nn.Sequential(*pyr_layers)\n",
    "        \n",
    "        self.final = nn.Conv2d(cndf, 1, 4, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.initial(input)\n",
    "        x = self.extra(x)\n",
    "        x = self.pyramid(x)\n",
    "        return self.final(x).mean(0).view(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeconvBlock(nn.Module):\n",
    "    def __init__(self, ni, no, ks, stride, pad, bn=True):\n",
    "        super().__init__()\n",
    "        self.conv = nn.ConvTranspose2d(ni, no, ks, stride, padding=pad, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(no)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv(x))\n",
    "        return self.bn(x) if self.bn else x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN_G(nn.Module):\n",
    "    def __init__(self, isize, nz, nc, ngf, n_extra_layers=0):\n",
    "        super().__init__()\n",
    "        assert isize % 16 == 0, \"isize has to be a multiple of 16\"\n",
    "\n",
    "        cngf, tisize = ngf//2, 4\n",
    "        while tisize!=isize: cngf*=2; tisize*=2\n",
    "        layers = [DeconvBlock(nz, cngf, 4, 1, 0)]\n",
    "\n",
    "        csize, cndf = 4, cngf\n",
    "        while csize < isize//2:\n",
    "            layers.append(DeconvBlock(cngf, cngf//2, 4, 2, 1))\n",
    "            cngf //= 2; csize *= 2\n",
    "\n",
    "        layers += [DeconvBlock(cngf, cngf, 3, 1, 1) for t in range(n_extra_layers)]\n",
    "        layers.append(nn.ConvTranspose2d(cngf, nc, 4, 2, 1, bias=False))\n",
    "        self.features = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, input): return F.tanh(self.features(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfms = tfms_from_stats(inception_stats, sz)\n",
    "md = ImageClassifierData.from_csv(path, 'TargetClass', csv, tfms=tfms, bs=bs, skip_header=False, continuous=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#md = md.resize(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation dataset\n",
    "list_val = iter(md.val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(list_val)\n",
    "idx=0\n",
    "\n",
    "fig,axes = plt.subplots(3,3, figsize=(12,12))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ima=md.val_ds.denorm(x)[i]\n",
    "    #ax.set_title(data.classes[y[i]])\n",
    "    ax.imshow(ima)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: 1 channel\n",
    "netG = DCGAN_G(sz, nz, 1, 64, 1).cuda()\n",
    "netD = DCGAN_D(sz, 1, 64, 1).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_noise(b): return V(torch.zeros(b, nz, 1, 1).normal_(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = netG(create_noise(4))\n",
    "pred_ims = md.trn_ds.denorm(preds)\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(6, 6))\n",
    "for i,ax in enumerate(axes.flat): ax.imshow(pred_ims[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gallery(x, nc=3):\n",
    "    n,h,w,c = x.shape\n",
    "    nr = n//nc\n",
    "    assert n == nr*nc\n",
    "    return (x.reshape(nr, nc, h, w, c)\n",
    "              .swapaxes(1,2)\n",
    "              .reshape(h*nr, w*nc, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: initial lr = 1e-4\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr = 1e-3)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(niter, first=True):\n",
    "    gen_iterations = 0\n",
    "    for epoch in trange(niter):\n",
    "        netD.train(); netG.train()\n",
    "        data_iter = iter(md.trn_dl)\n",
    "        i,n = 0,len(md.trn_dl)\n",
    "        with tqdm(total=n) as pbar:\n",
    "            while i < n:\n",
    "                set_trainable(netD, True)\n",
    "                set_trainable(netG, False)\n",
    "                d_iters = 100 if (first and (gen_iterations < 25) or (gen_iterations % 500 == 0)) else 5\n",
    "                j = 0\n",
    "                while (j < d_iters) and (i < n):\n",
    "                    j += 1; i += 1\n",
    "                    for p in netD.parameters(): p.data.clamp_(-0.01, 0.01)\n",
    "                    real = V(next(data_iter)[0])\n",
    "                    real_loss = netD(real)\n",
    "                    fake = netG(create_noise(real.size(0)))\n",
    "                    fake_loss = netD(V(fake.data))\n",
    "                    netD.zero_grad()\n",
    "                    lossD = real_loss-fake_loss\n",
    "                    lossD.backward()\n",
    "                    optimizerD.step()\n",
    "                    pbar.update()\n",
    "\n",
    "                set_trainable(netD, False)\n",
    "                set_trainable(netG, True)\n",
    "                netG.zero_grad()\n",
    "                lossG = netD(netG(create_noise(bs))).mean(0).view(1)\n",
    "                lossG.backward()\n",
    "                optimizerG.step()\n",
    "                gen_iterations += 1\n",
    "            \n",
    "        print(f'Loss_D {to_np(lossD)}; Loss_G {to_np(lossG)}; '\n",
    "              f'D_real {to_np(real_loss)}; Loss_D_fake {to_np(fake_loss)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_noise = create_noise(bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD.eval(); netG.eval();\n",
    "fake = netG(fixed_noise).data.cpu()\n",
    "faked = np.clip(md.trn_ds.denorm(fake),0,1)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(gallery(faked, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_trainable(netD, True)\n",
    "set_trainable(netG, True)\n",
    "# Note: initial lr = 1e-5\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr = 1e-4)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(100, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netD.eval(); netG.eval();\n",
    "fake = netG(fixed_noise).data.cpu()\n",
    "faked = np.clip(md.trn_ds.denorm(fake),0,1)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.imshow(gallery(faked, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(netG.state_dict(), TMP_PATH/'netG_200.h5')\n",
    "torch.save(netD.state_dict(), TMP_PATH/'netD_200.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
